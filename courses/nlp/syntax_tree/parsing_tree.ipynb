{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f10848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "pl.Config.set_tbl_rows(20)\n",
    "eng_dict = pl.read_csv(\n",
    "    \"eng_dict.txt\",\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    "    skip_lines=18,\n",
    "    infer_schema_length=10000000,\n",
    ").drop(\"column_2\")\n",
    "eng_dict = eng_dict.with_columns(cs.all().str.strip_chars())\n",
    "eng_dict = eng_dict.with_columns(\n",
    "    cs.matches(\"column_([4-9]|1\\\\d)\").str.split(\" \").list.first(),\n",
    ").with_columns(\n",
    "    cs.matches(\"column_([4-9]|1\\\\d)\").str.split(\"#\").list.first(),\n",
    ")\n",
    "dict_1 = eng_dict.select(pl.col(\"column_1\").alias(\"word\"), pl.col(\"column_4\").alias(\"pos\"))\n",
    "dict_2 = eng_dict.select(pl.col(\"column_3\").alias(\"word\"), pl.col(\"column_4\").alias(\"pos\"))\n",
    "dictionary = pl.concat([dict_2, dict_1]).unique(subset=\"word\", maintain_order=True)\n",
    "dictionary = dictionary.with_columns(\n",
    "    pl.col(\"word\").str.to_lowercase(),\n",
    "    pl.col(\"pos\").str.to_lowercase(),\n",
    ")\n",
    "\n",
    "dictionary = {dictionary[\"word\"]: dictionary[\"pos\"] for dictionary in dictionary.iter_rows(named=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cff1adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (11,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>word</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;det&quot;</td></tr><tr><td>&quot;a&quot;</td></tr><tr><td>&quot;n&quot;</td></tr><tr><td>&quot;v&quot;</td></tr><tr><td>&quot;n&quot;</td></tr><tr><td>&quot;det&quot;</td></tr><tr><td>&quot;a&quot;</td></tr><tr><td>&quot;n&quot;</td></tr><tr><td>&quot;prep&quot;</td></tr><tr><td>&quot;det&quot;</td></tr><tr><td>&quot;v&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (11,)\n",
       "Series: 'word' [str]\n",
       "[\n",
       "\t\"det\"\n",
       "\t\"a\"\n",
       "\t\"n\"\n",
       "\t\"v\"\n",
       "\t\"n\"\n",
       "\t\"det\"\n",
       "\t\"a\"\n",
       "\t\"n\"\n",
       "\t\"prep\"\n",
       "\t\"det\"\n",
       "\t\"v\"\n",
       "]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Grammar (extended to support nested PPs etc.)\n",
    "grammar = {\n",
    "    \"S\": [[\"NP\", \"VP\"], [\"NP\", \"VP\", \"PP\"]],\n",
    "    \"NP\": [[\"det\", \"NP3\"]],\n",
    "    \"NP3\": [[\"a\", \"NP3\"], [\"n\"], [\"n\", \"PP\"], [\"NP3\", \"PP\"]],\n",
    "    \"PP\": [[\"prep\", \"NP2\"], [\"PP\", \"PP\"]],\n",
    "    \"NP2\": [[\"d\", \"NP3\"]],\n",
    "    \"VP\": [[\"v\"], [\"v\", \"PP\"]],\n",
    "}\n",
    "\n",
    "# Sentence and POS tags\n",
    "words = \"An old man sat on the new chair in the house\".split()\n",
    "# words = [w.lower() for w in words]\n",
    "# pos = [\"det\", \"a\", \"n\", \"v\", \"prep\", \"det\", \"a\", \"n\", \"prep\", \"det\", \"n\"]\n",
    "words = pl.DataFrame({\"word\": words})\n",
    "words = words.with_columns(pl.col(\"word\").str.to_lowercase())\n",
    "pos = words.with_columns(pl.col(\"word\").replace(dictionary)).to_series()\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c8eb27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Chart (last column):\n",
      "\n",
      "✅ Sentence is REJECTED\n"
     ]
    }
   ],
   "source": [
    "# Earley State\n",
    "class State:\n",
    "    def __init__(self, lhs, rhs, dot, start):\n",
    "        self.lhs = lhs\n",
    "        self.rhs = rhs\n",
    "        self.dot = dot\n",
    "        self.start = start\n",
    "\n",
    "    def next_symbol(self):\n",
    "        return self.rhs[self.dot] if self.dot < len(self.rhs) else None\n",
    "\n",
    "    def is_complete(self):\n",
    "        return self.dot == len(self.rhs)\n",
    "\n",
    "    def advance(self):\n",
    "        return State(self.lhs, self.rhs, self.dot + 1, self.start)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.lhs, tuple(self.rhs), self.dot, self.start) == (\n",
    "            other.lhs,\n",
    "            tuple(other.rhs),\n",
    "            other.dot,\n",
    "            other.start,\n",
    "        )\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.lhs, tuple(self.rhs), self.dot, self.start))\n",
    "\n",
    "    def __repr__(self):\n",
    "        before = \" \".join(self.rhs[: self.dot])\n",
    "        after = \" \".join(self.rhs[self.dot :])\n",
    "        return f\"{self.lhs} → {before} • {after}, {self.start}\"\n",
    "\n",
    "\n",
    "# Earley Parser Function\n",
    "def earley_parse(words, pos, grammar, start_symbol=\"S\"):\n",
    "    n = len(words)\n",
    "    chart = [set() for _ in range(n + 1)]\n",
    "    chart[0].add(State(start_symbol, grammar[start_symbol][0], 0, 0))\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        added = True\n",
    "        while added:\n",
    "            added = False\n",
    "            current_items = list(chart[i])\n",
    "            for state in current_items:\n",
    "                if not state.is_complete():\n",
    "                    sym = state.next_symbol()\n",
    "\n",
    "                    # Predictor\n",
    "                    if sym in grammar:\n",
    "                        for prod in grammar[sym]:\n",
    "                            new_state = State(sym, prod, 0, i)\n",
    "                            if new_state not in chart[i]:\n",
    "                                chart[i].add(new_state)\n",
    "                                added = True\n",
    "\n",
    "                else:\n",
    "                    # Completer\n",
    "                    for prev in chart[state.start].copy():\n",
    "                        if prev.next_symbol() == state.lhs:\n",
    "                            new_state = prev.advance()\n",
    "                            if new_state not in chart[i]:\n",
    "                                chart[i].add(new_state)\n",
    "                                added = True\n",
    "\n",
    "        # Scanner (terminal symbols)\n",
    "        if i < n:\n",
    "            for state in chart[i]:\n",
    "                if state.next_symbol() == pos[i]:\n",
    "                    chart[i + 1].add(state.advance())\n",
    "\n",
    "    return chart\n",
    "\n",
    "\n",
    "# Run Parser\n",
    "chart = earley_parse(words, pos, grammar)\n",
    "\n",
    "# Display Final Chart State\n",
    "print(\"\\nFinal Chart (last column):\")\n",
    "for state in sorted(chart[-1], key=lambda x: x.lhs):\n",
    "    print(state)\n",
    "\n",
    "# Accept/Reject Check\n",
    "success = any(s.lhs == \"S\" and s.is_complete() and s.start == 0 for s in chart[-1])\n",
    "print(\"\\n✅ Sentence is\", \"ACCEPTED\" if success else \"REJECTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ Sentence is REJECTED\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from nltk.tree import Tree\n",
    "\n",
    "# Grammar (same as before)\n",
    "grammar = defaultdict(list)\n",
    "grammar[\"S\"] = [[\"NP\", \"VP\"], [\"NP\", \"VP\", \"PP\"]]\n",
    "grammar[\"NP\"] = [[\"d\", \"NP3\"]]\n",
    "grammar[\"NP3\"] = [[\"a\", \"NP3\"], [\"n\"], [\"n\", \"PP\"], [\"NP3\", \"PP\"]]\n",
    "grammar[\"PP\"] = [[\"p\", \"NP2\"], [\"PP\", \"PP\"]]\n",
    "grammar[\"NP2\"] = [[\"d\", \"NP3\"]]\n",
    "grammar[\"VP\"] = [[\"v\"], [\"v\", \"PP\"]]\n",
    "\n",
    "words = \"An old man sat on the new chair in the house\".split()\n",
    "\n",
    "# Earley State with backpointer\n",
    "BackState = namedtuple(\"BackState\", [\"lhs\", \"rhs\", \"dot\", \"start\", \"end\", \"children\"])\n",
    "\n",
    "\n",
    "def make_key(state):\n",
    "    return (state.lhs, tuple(state.rhs), state.dot, state.start)\n",
    "\n",
    "\n",
    "def earley_with_tree(words, pos, grammar, start_symbol=\"S\"):\n",
    "    n = len(words)\n",
    "    chart = [defaultdict(list) for _ in range(n + 1)]\n",
    "    start_state = BackState(start_symbol, grammar[start_symbol][0], 0, 0, 0, [])\n",
    "    chart[0][make_key(start_state)].append(start_state)\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        added = True\n",
    "        while added:\n",
    "            added = False\n",
    "            current_items = list(chart[i].values())\n",
    "            for states in current_items:\n",
    "                for state in states:\n",
    "                    if state.dot < len(state.rhs):\n",
    "                        sym = state.rhs[state.dot]\n",
    "\n",
    "                        # Predictor\n",
    "                        if sym in grammar:\n",
    "                            for prod in grammar[sym]:\n",
    "                                new_state = BackState(sym, prod, 0, i, i, [])\n",
    "                                key = make_key(new_state)\n",
    "                                if new_state not in chart[i][key]:\n",
    "                                    chart[i][key].append(new_state)\n",
    "                                    added = True\n",
    "\n",
    "                    else:\n",
    "                        # Completer\n",
    "                        for prev_states in chart[state.start].values():\n",
    "                            for prev in prev_states:\n",
    "                                if (\n",
    "                                    prev.dot < len(prev.rhs)\n",
    "                                    and prev.rhs[prev.dot] == state.lhs\n",
    "                                ):\n",
    "                                    new_children = prev.children + [state]\n",
    "                                    advanced = BackState(\n",
    "                                        prev.lhs,\n",
    "                                        prev.rhs,\n",
    "                                        prev.dot + 1,\n",
    "                                        prev.start,\n",
    "                                        i,\n",
    "                                        new_children,\n",
    "                                    )\n",
    "                                    key = make_key(advanced)\n",
    "                                    if advanced not in chart[i][key]:\n",
    "                                        chart[i][key].append(advanced)\n",
    "                                        added = True\n",
    "\n",
    "        # Scanner\n",
    "        if i < n:\n",
    "            for states in chart[i].values():\n",
    "                for state in states:\n",
    "                    if state.dot < len(state.rhs) and state.rhs[state.dot] == pos[i]:\n",
    "                        scanned = BackState(\n",
    "                            state.lhs,\n",
    "                            state.rhs,\n",
    "                            state.dot + 1,\n",
    "                            state.start,\n",
    "                            i + 1,\n",
    "                            state.children + [words[i]],\n",
    "                        )\n",
    "                        key = make_key(scanned)\n",
    "                        if scanned not in chart[i + 1][key]:\n",
    "                            chart[i + 1][key].append(scanned)\n",
    "\n",
    "    return chart\n",
    "\n",
    "\n",
    "# Build tree recursively\n",
    "def build_tree(state):\n",
    "    if isinstance(state, str):\n",
    "        return state\n",
    "    children = [build_tree(c) for c in state.children]\n",
    "    return Tree(state.lhs, children)\n",
    "\n",
    "\n",
    "# Run parser\n",
    "chart = earley_with_tree(words, pos, grammar)\n",
    "\n",
    "# Extract final complete parses\n",
    "final_states = []\n",
    "for states in chart[-1].values():\n",
    "    for state in states:\n",
    "        if state.lhs == \"S\" and state.dot == len(state.rhs) and state.start == 0:\n",
    "            final_states.append(state)\n",
    "\n",
    "if final_states:\n",
    "    print(\"\\n✅ Sentence is ACCEPTED\")\n",
    "    tree = build_tree(final_states[0])\n",
    "    tree.pretty_print()\n",
    "else:\n",
    "    print(\"\\n❌ Sentence is REJECTED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2227a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
