{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f10848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (317_322, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>column_1</th><th>column_3</th><th>column_4</th><th>column_5</th><th>column_6</th><th>column_7</th><th>column_8</th><th>column_9</th><th>column_10</th><th>column_11</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;enwraps &quot;</td><td>&quot;enwrap&quot;</td><td>&quot;V 3sg PRES&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;prolapse&#x27;s &quot;</td><td>&quot;prolapse&quot;</td><td>&quot;N 3sg GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;antibiotic&#x27;s &quot;</td><td>&quot;antibiotic&quot;</td><td>&quot;N 3sg GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;backdrop&#x27;s &quot;</td><td>&quot;backcloth&quot;</td><td>&quot;N 3sg GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;bubals&#x27; &quot;</td><td>&quot;bubal&quot;</td><td>&quot;N 3pl GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;collapses &quot;</td><td>&quot;collapse&quot;</td><td>&quot;N 3pl#collapse&quot;</td><td>&quot;V 3sg PRES&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;militarises &quot;</td><td>&quot;militarize&quot;</td><td>&quot;V 3sg PRES&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;open-eyed &quot;</td><td>&quot;open-eyed&quot;</td><td>&quot;A&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;bellbottomses&#x27; &quot;</td><td>&quot;bell-bottoms&quot;</td><td>&quot;N 3pl GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;packsaddles&#x27; &quot;</td><td>&quot;pack-saddle N 3pl GEN#packsadd…</td><td>&quot;N 3pl GEN&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (317_322, 10)\n",
       "┌────────────┬───────────┬───────────┬───────────┬───┬──────────┬──────────┬───────────┬───────────┐\n",
       "│ column_1   ┆ column_3  ┆ column_4  ┆ column_5  ┆ … ┆ column_8 ┆ column_9 ┆ column_10 ┆ column_11 │\n",
       "│ ---        ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---      ┆ ---      ┆ ---       ┆ ---       │\n",
       "│ str        ┆ str       ┆ str       ┆ str       ┆   ┆ str      ┆ str      ┆ str       ┆ str       │\n",
       "╞════════════╪═══════════╪═══════════╪═══════════╪═══╪══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ enwraps    ┆ enwrap    ┆ V 3sg     ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│            ┆           ┆ PRES      ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│ prolapse's ┆ prolapse  ┆ N 3sg GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ antibiotic ┆ antibioti ┆ N 3sg GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ 's         ┆ c         ┆           ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│ backdrop's ┆ backcloth ┆ N 3sg GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ bubals'    ┆ bubal     ┆ N 3pl GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ …          ┆ …         ┆ …         ┆ …         ┆ … ┆ …        ┆ …        ┆ …         ┆ …         │\n",
       "│ collapses  ┆ collapse  ┆ N 3pl#col ┆ V 3sg     ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│            ┆           ┆ lapse     ┆ PRES      ┆   ┆          ┆          ┆           ┆           │\n",
       "│ militarise ┆ militariz ┆ V 3sg     ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ s          ┆ e         ┆ PRES      ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│ open-eyed  ┆ open-eyed ┆ A         ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ bellbottom ┆ bell-bott ┆ N 3pl GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ ses'       ┆ oms       ┆           ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│ packsaddle ┆ pack-sadd ┆ N 3pl GEN ┆ null      ┆ … ┆ null     ┆ null     ┆ null      ┆ null      │\n",
       "│ s'         ┆ le N 3pl  ┆           ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│            ┆ GEN#packs ┆           ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "│            ┆ add…      ┆           ┆           ┆   ┆          ┆          ┆           ┆           │\n",
       "└────────────┴───────────┴───────────┴───────────┴───┴──────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "eng_dict = pl.read_csv(\n",
    "    \"eng_dict.txt\",\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    "    skip_lines=18,\n",
    "    infer_schema_length=10000000,\n",
    ").drop(\"column_2\")\n",
    "eng_dict = eng_dict.with_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85627b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "# Split the sentence into words\n",
    "words = sentence.split()\n",
    "words = [word.lower() for word in words]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641bac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "\n",
    "Rule = namedtuple(\"Rule\", [\"lhs\", \"rhs\"])\n",
    "\n",
    "\n",
    "class EarleyParser:\n",
    "    def __init__(self, grammar, start_symbol):\n",
    "        self.grammar = grammar\n",
    "        self.start_symbol = start_symbol\n",
    "        self.rules = self._build_rules(grammar)\n",
    "\n",
    "    def _build_rules(self, grammar):\n",
    "        rules = defaultdict(list)\n",
    "        for lhs, productions in grammar.items():\n",
    "            for prod in productions:\n",
    "                rules[lhs].append(prod)\n",
    "        return rules\n",
    "\n",
    "    def parse(self, tokens):\n",
    "        n = len(tokens)\n",
    "        chart = [set() for _ in range(n + 1)]\n",
    "        chart[0].add((\"S'\", [\"•\", self.start_symbol], 0))  # Start with S' → • S\n",
    "\n",
    "        def closure(i):\n",
    "            added = True\n",
    "            while added:\n",
    "                added = False\n",
    "                for state in list(chart[i]):\n",
    "                    dot_pos = state[1].index(\"•\")\n",
    "                    if dot_pos < len(state[1]) - 1:\n",
    "                        next_sym = state[1][dot_pos + 1]\n",
    "                        if next_sym in self.rules:\n",
    "                            for prod in self.rules[next_sym]:\n",
    "                                new_item = (next_sym, [\"•\"] + prod, i)\n",
    "                                if new_item not in chart[i]:\n",
    "                                    chart[i].add(new_item)\n",
    "                                    added = True\n",
    "\n",
    "        def scanner(i):\n",
    "            for state in list(chart[i]):\n",
    "                dot_pos = state[1].index(\"•\")\n",
    "                if dot_pos < len(state[1]) - 1:\n",
    "                    next_sym = state[1][dot_pos + 1]\n",
    "                    if i < n and next_sym == tokens[i]:\n",
    "                        new_state = (\n",
    "                            state[0],\n",
    "                            state[1][:dot_pos]\n",
    "                            + [next_sym, \"•\"]\n",
    "                            + state[1][dot_pos + 2 :],\n",
    "                            state[2],\n",
    "                        )\n",
    "                        chart[i + 1].add(new_state)\n",
    "\n",
    "        def completer(i):\n",
    "            for state in list(chart[i]):\n",
    "                if state[1][-1] == \"•\":\n",
    "                    for s in chart[state[2]]:\n",
    "                        dot_pos = s[1].index(\"•\")\n",
    "                        if dot_pos < len(s[1]) - 1 and s[1][dot_pos + 1] == state[0]:\n",
    "                            new_state = (\n",
    "                                s[0],\n",
    "                                s[1][:dot_pos] + [state[0], \"•\"] + s[1][dot_pos + 2 :],\n",
    "                                s[2],\n",
    "                            )\n",
    "                            chart[i].add(new_state)\n",
    "\n",
    "        for i in range(n + 1):\n",
    "            closure(i)\n",
    "            if i < n:\n",
    "                scanner(i)\n",
    "            completer(i)\n",
    "\n",
    "        # Check acceptance\n",
    "        final_state = (\"S'\", [self.start_symbol, \"•\"], 0)\n",
    "        return final_state in chart[n], chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afa2c4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m parser = EarleyParser(grammar, \u001b[33m\"\u001b[39m\u001b[33mS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m words = [\u001b[33m\"\u001b[39m\u001b[33mthe\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdog\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mchased\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mthe\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m accepted, parse_chart = \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccepted:\u001b[39m\u001b[33m\"\u001b[39m, accepted)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, state_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parse_chart):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mEarleyParser.parse\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m     20\u001b[39m n = \u001b[38;5;28mlen\u001b[39m(tokens)\n\u001b[32m     21\u001b[39m chart = [\u001b[38;5;28mset\u001b[39m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n + \u001b[32m1\u001b[39m)]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[43mchart\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mS\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m•\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstart_symbol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Start with S' → • S\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(i):\n\u001b[32m     25\u001b[39m     added = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "grammar = {\n",
    "    \"S\": [[\"NP\", \"VP\"]],\n",
    "    \"NP\": [[\"Det\", \"N\"]],\n",
    "    \"VP\": [[\"V\", \"NP\"]],\n",
    "    \"Det\": [[\"the\"]],\n",
    "    \"N\": [[\"dog\"], [\"cat\"]],\n",
    "    \"V\": [[\"chased\"], [\"saw\"]],\n",
    "}\n",
    "\n",
    "parser = EarleyParser(grammar, \"S\")\n",
    "words = [\"the\", \"dog\", \"chased\", \"the\", \"cat\"]\n",
    "accepted, parse_chart = parser.parse(words)\n",
    "\n",
    "print(\"Accepted:\", accepted)\n",
    "for i, state_set in enumerate(parse_chart):\n",
    "    print(f\"I{i}:\")\n",
    "    for item in state_set:\n",
    "        print(\" \", item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(\n",
    "        self, label, rules, dot_idx, start_idx, end_idx, idx, made_from, producer\n",
    "    ):\n",
    "        self.label = label\n",
    "        self.rules = rules\n",
    "        self.dot_idx = dot_idx\n",
    "        self.start_idx = start_idx\n",
    "        self.end_idx = end_idx\n",
    "        self.idx = idx\n",
    "        self.made_from = made_from\n",
    "        self.producer = producer\n",
    "\n",
    "    def next(self):\n",
    "        \"\"\"Returns the tag after the dot\"\"\"\n",
    "        return self.rules[self.dot_idx]\n",
    "\n",
    "    def complete(self):\n",
    "        return len(self.rules) == self.dot_idx\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (\n",
    "            self.label == other.label\n",
    "            and self.rules == other.rules\n",
    "            and self.dot_idx == other.dot_idx\n",
    "            and self.start_idx == other.start_idx\n",
    "            and self.end_idx == other.end_idx\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        rule_string = \"\"\n",
    "        for i, rule in enumerate(self.rules):\n",
    "            if i == self.dot_idx:\n",
    "                rule_string += \"\\\\bullet \"\n",
    "            rule_string += rule + \" \"\n",
    "        if self.dot_idx == len(self.rules):\n",
    "            rule_string += \"\\\\bullet\"\n",
    "        return \"S%d %s -> %s [%d, %d] %s %s\" % (\n",
    "            self.idx,\n",
    "            self.label,\n",
    "            rule_string,\n",
    "            self.start_idx,\n",
    "            self.end_idx,\n",
    "            self.made_from,\n",
    "            self.producer,\n",
    "        )\n",
    "\n",
    "\n",
    "class Earley:\n",
    "    def __init__(self, words, grammar, terminals):\n",
    "        self.chart = [[] for _ in range(len(words) + 1)]\n",
    "        self.current_id = 0\n",
    "        self.words = words\n",
    "        self.grammar = grammar\n",
    "        self.terminals = terminals\n",
    "\n",
    "    def get_new_id(self):\n",
    "        self.current_id += 1\n",
    "        return self.current_id - 1\n",
    "\n",
    "    def is_terminal(self, tag):\n",
    "        return tag in self.terminals\n",
    "\n",
    "    def is_complete(self, state):\n",
    "        return len(state.rules) == state.dot_idx\n",
    "\n",
    "    def enqueue(self, state, chart_entry):\n",
    "        if state not in self.chart[chart_entry]:\n",
    "            self.chart[chart_entry].append(state)\n",
    "        else:\n",
    "            self.current_id -= 1\n",
    "\n",
    "    def predictor(self, state):\n",
    "        for production in self.grammar[state.next()]:\n",
    "            self.enqueue(\n",
    "                State(\n",
    "                    state.next(),\n",
    "                    production,\n",
    "                    0,\n",
    "                    state.end_idx,\n",
    "                    state.end_idx,\n",
    "                    self.get_new_id(),\n",
    "                    [],\n",
    "                    \"predictor\",\n",
    "                ),\n",
    "                state.end_idx,\n",
    "            )\n",
    "\n",
    "    def scanner(self, state):\n",
    "        if self.words[state.end_idx] in self.grammar[state.next()]:\n",
    "            self.enqueue(\n",
    "                State(\n",
    "                    state.next(),\n",
    "                    [self.words[state.end_idx]],\n",
    "                    1,\n",
    "                    state.end_idx,\n",
    "                    state.end_idx + 1,\n",
    "                    self.get_new_id(),\n",
    "                    [],\n",
    "                    \"scanner\",\n",
    "                ),\n",
    "                state.end_idx + 1,\n",
    "            )\n",
    "\n",
    "    def completer(self, state):\n",
    "        for s in self.chart[state.start_idx]:\n",
    "            if (\n",
    "                not s.complete()\n",
    "                and s.next() == state.label\n",
    "                and s.end_idx == state.start_idx\n",
    "                and s.label != \"gamma\"\n",
    "            ):\n",
    "                self.enqueue(\n",
    "                    State(\n",
    "                        s.label,\n",
    "                        s.rules,\n",
    "                        s.dot_idx + 1,\n",
    "                        s.start_idx,\n",
    "                        state.end_idx,\n",
    "                        self.get_new_id(),\n",
    "                        s.made_from + [state.idx],\n",
    "                        \"completer\",\n",
    "                    ),\n",
    "                    state.end_idx,\n",
    "                )\n",
    "\n",
    "    def parse(self):\n",
    "        self.enqueue(\n",
    "            State(\"gamma\", [\"S\"], 0, 0, 0, self.get_new_id(), [], \"dummy start state\"),\n",
    "            0,\n",
    "        )\n",
    "\n",
    "        for i in range(len(self.words) + 1):\n",
    "            for state in self.chart[i]:\n",
    "                if not state.complete() and not self.is_terminal(state.next()):\n",
    "                    self.predictor(state)\n",
    "                elif (\n",
    "                    i != len(self.words)\n",
    "                    and not state.complete()\n",
    "                    and self.is_terminal(state.next())\n",
    "                ):\n",
    "                    self.scanner(state)\n",
    "                else:\n",
    "                    self.completer(state)\n",
    "\n",
    "    def __str__(self):\n",
    "        res = \"\"\n",
    "\n",
    "        for i, chart in enumerate(self.chart):\n",
    "            res += \"\\nChart[%d]\\n\" % i\n",
    "            for state in chart:\n",
    "                res += str(state) + \"\\n\"\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "def test():\n",
    "    grammar = {\n",
    "        \"S\": [[\"NP\", \"VP\"], [\"Aux\", \"NP\", \"VP\"], [\"VP\"]],\n",
    "        \"NP\": [[\"Det\", \"Nominal\"], [\"Proper-Noun\"]],\n",
    "        \"Nominal\": [[\"Noun\"], [\"Noun\", \"Nominal\"]],\n",
    "        \"VP\": [[\"Verb\"], [\"Verb\", \"NP\"]],\n",
    "        \"Det\": [\"that\", \"this\", \"a\"],\n",
    "        \"Noun\": [\"book\", \"flight\", \"meal\", \"money\"],\n",
    "        \"Verb\": [\"book\", \"include\", \"prever\"],\n",
    "        \"Aux\": [\"does\"],\n",
    "        \"Prep\": [\"from\", \"to\", \"on\"],\n",
    "        \"Proper-Noun\": [\"Houston\", \"TWA\"],\n",
    "    }\n",
    "    terminals = [\"Det\", \"Noun\", \"Verb\", \"Aux\", \"Prep\", \"Proper-Noun\"]\n",
    "\n",
    "    earley = Earley([\"book\", \"that\", \"flight\"], grammar, terminals)\n",
    "    earley.parse()\n",
    "\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
