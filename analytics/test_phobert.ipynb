{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259b8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import py_vncorenlp\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    logging,\n",
    ")\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS = 6\n",
    "N_SPLITS = 10\n",
    "\n",
    "phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"NlpHUST/vibert4news-base-cased\", num_labels=5\n",
    ")\n",
    "\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "seed_everything(86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8348250f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌──────────────────┬───────────────┐\n",
      "│ segmented_review ┆ review_rating │\n",
      "│ ---              ┆ ---           │\n",
      "│ list[i32]        ┆ f64           │\n",
      "╞══════════════════╪═══════════════╡\n",
      "│ [0, 6676, … 2]   ┆ 4.0           │\n",
      "│ [0, 48640, … 2]  ┆ 5.0           │\n",
      "│ [0, 290, … 2]    ┆ 5.0           │\n",
      "│ [0, 2174, … 2]   ┆ 4.0           │\n",
      "│ [0, 6676, … 2]   ┆ 1.0           │\n",
      "└──────────────────┴───────────────┘\n"
     ]
    }
   ],
   "source": [
    "dataset = (\n",
    "    pl.read_parquet(\n",
    "        \"hf://datasets/khangnghiem/public/transform/company_reviews/transformed_company_reviews.parquet\"\n",
    "    )\n",
    "    .select(\"segmented_review\", \"review_rating\")\n",
    "    .with_columns(\n",
    "        pl.col(\"segmented_review\")\n",
    "        .list.join(\" \")\n",
    "        .map_elements(tokenizer.encode, return_dtype=pl.List(pl.Int32))\n",
    "    )\n",
    ")\n",
    "print(dataset.sample(5))\n",
    "# Define the lengths for train, validation, and test splits\n",
    "total_length = len(dataset)\n",
    "train_length = int(0.8 * total_length)  # 80% for training\n",
    "val_length = int(0.1 * total_length)  # 10% for validation\n",
    "test_length = total_length - train_length - val_length  # Remaining 10% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset, [train_length, val_length, test_length]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b4c702",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 143] at entry 0 and [1, 242] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m sentiment_model.train()\n\u001b[32m     48\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[39m, in \u001b[36mdefault_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault_collate\u001b[39m(batch):\n\u001b[32m    338\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[33;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m \u001b[33;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    208\u001b[39m transposed = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(*batch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[32m    214\u001b[39m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[39m, in \u001b[36mcollate\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/hcmus/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[39m, in \u001b[36mcollate_tensor_fn\u001b[39m\u001b[34m(batch, collate_fn_map)\u001b[39m\n\u001b[32m    270\u001b[39m     storage = elem._typed_storage()._new_shared(numel, device=elem.device)\n\u001b[32m    271\u001b[39m     out = elem.new(storage).resize_(\u001b[38;5;28mlen\u001b[39m(batch), *\u001b[38;5;28mlist\u001b[39m(elem.size()))\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [1, 143] at entry 0 and [1, 242] at entry 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Define a simple PyTorch Dataset\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review = self.data[idx][\"segmented_review\"]\n",
    "        label = self.data[idx][\"review_rating\"] - 1  # Adjust labels to be 0-indexed\n",
    "        return torch.tensor(review, dtype=torch.long), torch.tensor(\n",
    "            label, dtype=torch.long\n",
    "        )\n",
    "\n",
    "\n",
    "# Create DataLoader for training, validation, and testing\n",
    "train_loader = DataLoader(ReviewDataset(train_dataset), batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(ReviewDataset(val_dataset), batch_size=16)\n",
    "test_loader = DataLoader(ReviewDataset(test_dataset), batch_size=16)\n",
    "\n",
    "\n",
    "# Define the model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, base_model, num_labels):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])  # Use [CLS] token\n",
    "        return logits\n",
    "\n",
    "\n",
    "sentiment_model = SentimentClassifier(phobert, num_labels=5).to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(sentiment_model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    sentiment_model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, labels = batch\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = sentiment_model(input_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {total_loss / len(train_loader)}\")\n",
    "\n",
    "# Validation loop\n",
    "sentiment_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, labels = batch\n",
    "        input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "\n",
    "        logits = sentiment_model(input_ids)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
    "print(f\"Validation F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35a2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e6f904035a4f2eaa440e9a730e3ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/551 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acec245efb1c4244a14f3de11d5abbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "sentence = \"Chúng_tôi là những nghiên_cứu_viên .\"\n",
    "\n",
    "input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = phobert(input_ids)  # Models outputs are now tuples\n",
    "\n",
    "## With TensorFlow 2.0+:\n",
    "# from transformers import TFAutoModel\n",
    "# phobert = TFAutoModel.from_pretrained(\"vinai/phobert-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4fdca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 3.8362e-02,  7.0703e-01, -1.3202e-01,  ..., -9.7446e-02,\n",
       "           2.5193e-01,  3.4828e-01],\n",
       "         [ 2.1041e-01,  2.3984e-01,  9.1066e-03,  ..., -3.2366e-04,\n",
       "          -1.7492e-01,  4.0127e-02],\n",
       "         [ 2.3745e-01,  9.8413e-03, -1.6509e-01,  ..., -4.3378e-02,\n",
       "          -7.5783e-02,  4.6839e-02],\n",
       "         ...,\n",
       "         [ 2.3041e-01,  3.7583e-01,  1.7601e-02,  ...,  7.8471e-02,\n",
       "           1.8661e-01,  5.2052e-02],\n",
       "         [-2.3020e-01,  5.0276e-01,  1.0913e-01,  ..., -7.3261e-02,\n",
       "           1.4339e-01,  1.8320e-01],\n",
       "         [ 1.8813e-01,  6.2870e-01, -2.4809e-01,  ..., -4.8115e-02,\n",
       "           1.6404e-01,  4.7204e-01]]]), pooler_output=tensor([[ 6.3029e-02, -1.1201e-01, -5.8864e-02,  3.0363e-02, -1.7679e-01,\n",
       "          1.0654e-01, -8.5272e-02, -1.4876e-02, -1.6943e-01,  1.4987e-01,\n",
       "         -2.0341e-01,  1.7840e-01, -5.9578e-02, -3.6399e-01, -5.2988e-02,\n",
       "         -1.2848e-01, -3.5642e-02,  1.3621e-01,  5.5654e-02,  1.2824e-01,\n",
       "         -8.5278e-02,  1.4056e-01, -7.7501e-03,  7.1241e-02,  8.7172e-02,\n",
       "          5.7157e-03,  1.0738e-01, -1.2204e-01,  1.9550e-02,  1.7918e-01,\n",
       "         -1.7683e-01, -9.9477e-02,  9.6815e-02, -9.5404e-02, -7.6988e-02,\n",
       "          4.4225e-02, -2.1012e-02,  9.3920e-02,  5.1061e-02,  6.6968e-02,\n",
       "         -1.9895e-01, -2.2289e-01,  1.9581e-02, -4.8939e-02,  2.1800e-01,\n",
       "         -2.3614e-01,  2.5356e-02,  1.7418e-01, -2.6298e-01, -1.8622e-01,\n",
       "          7.6557e-02, -8.0622e-02,  2.8635e-01, -4.8496e-02, -1.2409e-02,\n",
       "          3.5316e-01,  1.4035e-01,  3.8043e-01,  1.6133e-02,  2.5827e-01,\n",
       "         -5.4824e-02,  6.8705e-02,  4.0811e-02,  1.7859e-01,  2.5718e-01,\n",
       "          7.2627e-02,  5.0265e-01, -4.3708e-02, -4.7651e-02,  1.1539e-02,\n",
       "          1.7822e-01, -7.8364e-02,  1.9404e-01, -2.3914e-01, -5.7617e-02,\n",
       "          1.9054e-01,  2.0976e-01,  1.4752e-01,  1.2087e-01,  5.2508e-02,\n",
       "         -6.5083e-02, -2.3019e-01,  9.4633e-02,  1.5139e-01, -2.8885e-02,\n",
       "         -1.4859e-01, -1.3684e-01,  6.2205e-03, -1.7771e-01, -2.1467e-02,\n",
       "         -1.8449e-01,  2.0103e-01,  1.3074e-01,  1.4244e-02,  3.6894e-02,\n",
       "         -1.5345e-01, -5.2448e-02, -7.0932e-02, -1.0476e-01,  6.5675e-02,\n",
       "         -1.8408e-02, -1.2299e-01,  5.8105e-02, -2.7004e-02,  2.6501e-01,\n",
       "          2.6432e-01, -1.4934e-01,  1.5406e-01,  8.5148e-02,  1.4962e-03,\n",
       "         -5.1497e-02, -8.6725e-02, -1.1946e-01, -8.8029e-03,  8.4261e-02,\n",
       "          6.9179e-02,  2.5715e-01, -1.5209e-01,  7.9819e-02, -1.3215e-01,\n",
       "          1.2857e-01,  9.9341e-02,  5.5833e-03, -5.3934e-02, -5.5750e-02,\n",
       "         -2.6561e-02, -1.4217e-01, -5.0877e-02,  4.2325e-02, -2.6453e-01,\n",
       "         -6.7575e-02, -2.2349e-01,  5.6704e-02,  1.3629e-01, -1.8350e-01,\n",
       "          9.1447e-02, -1.4652e-01,  1.1961e-01, -1.7678e-01, -9.0074e-02,\n",
       "         -6.3754e-03,  1.6077e-01, -1.1883e-01, -2.1551e-01,  1.8870e-01,\n",
       "         -1.7951e-01,  6.7779e-02,  1.3357e-01,  2.3697e-01, -1.2165e-01,\n",
       "         -6.1304e-02,  3.2941e-02, -5.3494e-02,  8.2193e-04,  7.0949e-02,\n",
       "          8.0625e-02, -7.5942e-02, -8.4414e-02,  1.4549e-01, -2.2673e-02,\n",
       "          1.0409e-01,  8.2179e-02,  1.7386e-01, -1.0414e-01,  3.3099e-01,\n",
       "          2.2499e-01,  1.4004e-01, -6.7673e-02,  5.0538e-02, -3.8044e-02,\n",
       "          1.7904e-01, -3.1717e-02, -2.5577e-01,  1.4063e-02,  2.3424e-01,\n",
       "         -6.1660e-02,  1.0102e-01,  1.6990e-01, -9.1864e-02, -6.2275e-02,\n",
       "          1.4487e-01, -1.0998e-01, -3.5968e-02,  4.7278e-02,  2.7184e-02,\n",
       "          1.6701e-01,  1.3516e-01,  3.3895e-01, -3.2457e-02, -8.3173e-02,\n",
       "          8.4912e-03,  1.6597e-01,  1.9667e-01,  1.0326e-01,  9.0043e-02,\n",
       "          5.8588e-02, -1.0900e-01,  1.6210e-01,  2.0143e-01, -1.2820e-01,\n",
       "          1.1663e-01, -1.3242e-01, -1.0835e-01,  2.8524e-01,  1.7547e-01,\n",
       "          7.7660e-02, -2.8080e-02,  8.6117e-02,  7.6582e-02, -7.6568e-02,\n",
       "         -2.8985e-01, -2.6929e-02,  6.6882e-02,  2.1456e-01,  5.7102e-02,\n",
       "         -3.8517e-02,  1.3332e-01,  1.6856e-01,  1.2053e-01,  9.5037e-02,\n",
       "         -8.2067e-02, -2.4361e-01,  5.1579e-03, -8.3772e-02, -2.7552e-01,\n",
       "          1.6065e-01,  7.7376e-02,  5.0770e-02, -6.1515e-02, -1.4695e-01,\n",
       "         -1.4117e-01, -1.2852e-01,  6.8404e-02, -5.6519e-02, -5.8017e-02,\n",
       "          8.2818e-02, -1.5469e-01, -3.0018e-02,  9.2056e-02,  4.8520e-02,\n",
       "          2.1437e-01, -5.4460e-02,  5.5201e-02,  3.5194e-02,  6.0095e-02,\n",
       "          5.2895e-02, -1.0813e-01,  2.0120e-01, -1.4063e-01, -1.6511e-01,\n",
       "          1.1903e-02,  2.8231e-02, -1.3120e-01,  2.1522e-02, -2.2875e-01,\n",
       "          8.8482e-03,  9.3908e-02,  3.3337e-01,  4.2284e-02, -4.6282e-02,\n",
       "          3.8699e-02,  9.0183e-02, -1.2783e-02, -1.2092e-01,  1.0109e-01,\n",
       "          1.9474e-01,  7.5786e-02, -5.0947e-02, -3.9999e-02,  2.9727e-02,\n",
       "         -2.0187e-02, -2.3716e-01, -1.1095e-01, -1.2016e-01, -2.8095e-02,\n",
       "          2.4763e-01,  9.1695e-04,  7.7484e-02,  6.9101e-02,  7.2022e-02,\n",
       "          9.7072e-02, -1.5387e-01,  1.4405e-01,  1.9062e-02,  2.4780e-01,\n",
       "         -1.5359e-01,  2.3420e-01, -1.5125e-01,  4.9493e-02, -2.8881e-01,\n",
       "         -2.7444e-01, -1.7453e-01,  8.3377e-02, -8.2640e-02,  2.3907e-01,\n",
       "         -2.2161e-01, -3.1371e-01,  2.6610e-02, -3.4141e-01, -2.0905e-02,\n",
       "         -6.5322e-02, -3.1872e-01, -1.2406e-01,  6.6286e-02,  1.2708e-01,\n",
       "         -2.5049e-01,  1.8348e-01,  2.2199e-01, -1.3093e-01,  2.2063e-01,\n",
       "         -4.2551e-02,  1.3000e-01, -1.7256e-01,  1.8946e-01,  8.7969e-02,\n",
       "          2.6693e-01, -5.7154e-02, -2.6309e-01,  4.3207e-02, -2.7899e-02,\n",
       "         -3.2193e-01,  3.3467e-02,  1.7066e-01,  1.9125e-01,  3.5253e-02,\n",
       "          7.7428e-02, -8.4071e-02, -3.0079e-01,  8.2970e-02, -4.7993e-03,\n",
       "         -9.2676e-02,  1.4857e-02,  2.5829e-01, -1.4826e-01, -1.4200e-02,\n",
       "          2.1768e-02, -2.5633e-01,  1.4616e-01, -5.3215e-02, -1.3131e-01,\n",
       "          1.8679e-01, -7.1031e-02, -4.9011e-02, -1.1782e-01,  4.2726e-02,\n",
       "         -1.5412e-01, -1.0654e-01, -3.7663e-04, -1.9512e-03,  5.7875e-02,\n",
       "          1.8055e-01,  3.3992e-01,  4.0248e-02,  1.9563e-01, -3.0166e-01,\n",
       "          4.4694e-02, -6.3910e-02, -4.3119e-02,  5.0928e-02, -9.5000e-02,\n",
       "         -1.4580e-01,  1.6516e-01, -6.6012e-02,  1.0663e-01, -2.4886e-01,\n",
       "          1.8422e-01,  5.2418e-03, -1.2505e-01,  4.0046e-02, -1.1421e-01,\n",
       "          2.6472e-01, -1.8355e-01,  6.5476e-03, -1.8621e-01, -1.9865e-02,\n",
       "         -1.0770e-01,  1.4380e-01, -7.2037e-02,  1.5228e-01, -6.9386e-02,\n",
       "          3.4456e-02,  1.0160e-01, -1.3257e-01, -1.2546e-01, -1.8745e-01,\n",
       "          1.3320e-01, -7.4432e-03, -7.6803e-02, -5.0530e-02,  2.1350e-01,\n",
       "         -6.8026e-02, -1.7309e-01,  3.9077e-02, -2.9685e-01, -1.1272e-01,\n",
       "         -2.1411e-01,  2.1517e-01,  1.3533e-01, -1.3140e-01, -3.3798e-01,\n",
       "         -5.1745e-02, -3.5769e-04,  5.8342e-02,  1.0616e-01, -2.2815e-02,\n",
       "          1.1166e-01,  1.6300e-02, -2.2941e-01, -1.1556e-02, -1.4564e-01,\n",
       "          2.7036e-01,  4.4582e-02, -1.7210e-01,  1.2849e-01, -2.1469e-01,\n",
       "         -2.0190e-01, -2.2656e-01,  2.0577e-02,  2.1511e-02, -1.2120e-01,\n",
       "          6.3158e-02,  7.6214e-02,  2.7468e-01,  1.4727e-01, -3.7020e-02,\n",
       "          1.0730e-01,  1.1798e-01,  7.5885e-02,  2.0719e-01, -7.0913e-02,\n",
       "         -8.6842e-02, -2.4048e-01, -1.6372e-02,  3.0072e-01,  5.8656e-02,\n",
       "          1.1877e-02,  7.5475e-02,  1.4017e-01,  2.0798e-01, -2.6863e-02,\n",
       "          1.8573e-01, -1.2451e-01, -5.2222e-02, -1.6712e-01, -7.9280e-02,\n",
       "          1.3147e-02, -4.1668e-02, -2.1653e-01, -2.4402e-02,  1.9633e-02,\n",
       "          1.8868e-01,  6.7276e-02, -8.7144e-02,  7.0724e-02, -8.4787e-02,\n",
       "          8.3087e-02,  3.5472e-01, -2.8199e-01, -1.2079e-01, -7.5825e-02,\n",
       "          3.8019e-02, -8.8395e-03, -7.6883e-02,  3.5567e-02, -3.2352e-02,\n",
       "          3.2287e-01, -2.2107e-02,  1.6634e-01, -1.7712e-01, -1.0123e-02,\n",
       "          1.0626e-01,  6.2159e-02,  2.0591e-01,  1.2647e-01, -1.4715e-01,\n",
       "         -2.5048e-01,  1.5277e-01,  9.2678e-02, -7.3669e-02,  1.4045e-01,\n",
       "         -1.4400e-01, -8.1755e-02,  1.7816e-01, -7.1753e-02,  1.4304e-01,\n",
       "         -8.9175e-02,  1.9614e-01, -2.0234e-01, -1.0315e-01,  1.9468e-01,\n",
       "         -3.5981e-02,  8.5831e-02, -1.6270e-01,  5.3435e-02,  7.8503e-02,\n",
       "         -2.5036e-01, -1.4014e-01,  3.2574e-01, -5.6993e-02,  1.8671e-01,\n",
       "         -1.6950e-02, -1.5147e-01,  2.2956e-01,  1.2498e-01, -1.2075e-01,\n",
       "         -3.7466e-01,  7.0238e-03, -2.9276e-02, -8.8320e-03, -1.3677e-01,\n",
       "          2.2909e-01, -4.8748e-02, -1.1890e-01,  1.1117e-01,  1.3412e-01,\n",
       "          2.1335e-01,  1.9819e-01, -2.2196e-01, -1.3100e-01,  4.0146e-02,\n",
       "         -1.8632e-01, -1.9717e-02, -1.0790e-01,  7.7112e-02, -3.4221e-02,\n",
       "          5.2781e-02,  1.6199e-01, -2.0134e-03,  2.1912e-01, -9.0359e-02,\n",
       "         -1.1811e-01, -1.9649e-02, -2.3530e-01, -3.2387e-02, -1.1661e-01,\n",
       "         -3.5554e-02,  8.8080e-03,  1.0778e-01, -5.8339e-02,  7.0337e-02,\n",
       "         -9.7312e-03,  2.6912e-03, -7.1204e-02, -2.0692e-01, -2.1001e-03,\n",
       "          2.1123e-02, -1.1754e-01, -3.5487e-02, -6.0325e-02, -1.3257e-01,\n",
       "         -1.6432e-01, -1.2911e-01,  1.8251e-02, -1.6425e-01, -2.5155e-01,\n",
       "         -1.6261e-01,  7.0511e-02, -8.4540e-02,  6.4747e-02,  1.4310e-01,\n",
       "         -1.3760e-02,  1.8655e-01,  1.3302e-01, -4.0032e-02,  1.0646e-02,\n",
       "          1.6419e-01, -1.1285e-01, -1.8255e-01,  1.1182e-02,  9.8668e-03,\n",
       "         -3.8984e-02, -5.5979e-02,  6.2956e-03,  1.7185e-01,  7.6471e-02,\n",
       "         -5.2378e-02,  1.0682e-01,  2.0529e-01,  1.2711e-02,  1.7312e-01,\n",
       "         -3.1316e-01,  1.8011e-01,  5.6294e-04, -6.0455e-02,  9.2824e-02,\n",
       "          1.3436e-01, -2.3185e-01, -1.1323e-01,  5.3713e-02,  6.5639e-02,\n",
       "         -1.3290e-01, -1.0228e-01, -1.5285e-01, -9.4817e-02,  1.2831e-01,\n",
       "         -4.1292e-02, -3.7997e-01,  2.9438e-01, -7.5122e-03,  7.5531e-03,\n",
       "         -9.2089e-02,  9.9687e-02,  2.2664e-01, -9.7215e-02, -4.2236e-02,\n",
       "         -1.0361e-02, -1.1550e-01, -3.7306e-01,  1.0809e-01, -3.5834e-01,\n",
       "         -1.6653e-01, -1.0620e-01, -3.1317e-01, -4.0537e-02, -1.1197e-01,\n",
       "         -7.3259e-03, -6.4054e-04,  1.1440e-01,  1.6463e-01,  1.6446e-01,\n",
       "          4.7118e-02, -4.6936e-02, -3.4926e-02,  4.9766e-03, -1.8300e-01,\n",
       "          1.1292e-01,  2.4681e-01, -1.3207e-01, -2.0219e-02,  2.0138e-02,\n",
       "          1.6192e-01,  1.4514e-01, -5.8662e-02,  5.6463e-02, -5.8507e-02,\n",
       "         -1.7161e-01,  4.5997e-02,  1.4017e-01, -6.6726e-02,  5.6641e-02,\n",
       "          9.1511e-02,  3.1140e-02,  1.8593e-02,  6.8479e-02,  3.7131e-02,\n",
       "          1.3589e-02, -9.0202e-02, -4.2209e-02, -1.3847e-01, -3.6347e-02,\n",
       "          1.8613e-01,  7.5030e-02,  1.7229e-01,  1.9912e-01, -1.9761e-01,\n",
       "         -6.4242e-03, -1.4455e-01, -8.7090e-03,  1.3669e-01, -6.7090e-02,\n",
       "         -8.4718e-02, -1.9303e-01, -9.6237e-02,  1.4404e-01, -8.9082e-02,\n",
       "         -3.0198e-02, -9.1229e-02,  2.7739e-02,  1.3323e-02,  1.0240e-01,\n",
       "          6.4160e-02, -3.2985e-01,  2.7275e-02,  2.0098e-01,  4.6219e-02,\n",
       "          5.9141e-02,  1.0307e-02,  3.8410e-02,  2.9682e-01, -4.0225e-01,\n",
       "         -1.9540e-01, -1.5270e-01, -8.4662e-02,  7.1736e-02,  2.5883e-01,\n",
       "         -2.6030e-01, -1.2135e-01, -8.7297e-02, -2.5463e-02, -6.2853e-02,\n",
       "          3.8908e-02,  6.6641e-02,  3.2182e-02,  4.4242e-03,  1.2006e-01,\n",
       "          3.5062e-02,  9.8817e-02, -1.7788e-01, -8.9607e-02,  1.7132e-02,\n",
       "         -6.3222e-02,  4.7427e-02,  1.4879e-01, -3.5284e-01, -1.2086e-01,\n",
       "         -1.6745e-01, -8.6191e-02,  1.1465e-01,  1.0416e-01, -2.1833e-01,\n",
       "          8.2591e-02, -9.7264e-02, -6.1459e-02, -2.9240e-02,  5.8277e-03,\n",
       "          1.5218e-01, -1.1720e-01,  1.9502e-01,  1.9542e-01,  1.2656e-01,\n",
       "          1.7823e-01, -3.4028e-01, -5.3538e-02,  1.4263e-01,  3.5510e-02,\n",
       "          3.3323e-01, -3.2223e-02, -2.3214e-01, -1.4288e-01, -2.9207e-02,\n",
       "          1.0378e-02, -2.3543e-02,  7.4482e-02,  1.3585e-01, -1.0505e-01,\n",
       "         -7.7102e-02, -2.5587e-02,  1.8305e-02,  5.1958e-02,  2.4187e-02,\n",
       "         -2.4962e-01,  2.5674e-01,  2.5072e-01,  1.9770e-01, -1.1574e-01,\n",
       "          2.0162e-01,  3.6585e-03,  2.8836e-02,  8.7720e-02,  4.1176e-03,\n",
       "          4.3278e-02,  1.4410e-01,  4.8055e-02, -2.7967e-02,  2.2143e-02,\n",
       "         -3.2136e-01,  1.9534e-01, -1.2845e-01, -1.0972e-01, -7.6112e-02,\n",
       "          2.8422e-03,  5.5090e-02,  2.4199e-02, -1.7824e-01, -2.3434e-01,\n",
       "         -1.7360e-01,  4.1685e-02,  1.7876e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    preprocessed = text\n",
    "    inputs = tokenizer(preprocessed, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        predicted = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    return predicted, probs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
